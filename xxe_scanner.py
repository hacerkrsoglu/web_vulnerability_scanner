# -*- coding: utf-8 -*-
"""
Created on Wed Sep 11 23:37:11 2024

@author: Hacer
"""

import argparse
import requests
from bs4 import BeautifulSoup
from requests.packages.urllib3.exceptions import InsecureRequestWarning
import warnings
from urllib.parse import urlparse, urlunparse, urlencode, urljoin

# Sertifika uyarılarını bastır
warnings.simplefilter('ignore', InsecureRequestWarning)

def sanitize_url(url):
    """
    URL'yi temizlemek ve standart bir formata dönüştürmek için kullanılır.
    """
    parsed_url = urlparse(url)
    scheme = parsed_url.scheme
    netloc = parsed_url.netloc
    path = parsed_url.path.rstrip('/')
    clean_url = urlunparse((scheme, netloc, path, '', '', ''))
    return clean_url

def send_xml_payload(url, xml_data):
    headers = {'Content-Type': 'application/xml'}
    try:
        response = requests.post(url, data=xml_data, headers=headers, verify=False)
        return response
    except requests.exceptions.RequestException as e:
        print(f"(-) İstek gönderilemedi: {e}")
        return None

def check_xxe_injection(url, payloads, forms, links):
    vulnerabilities_found = []
    sanitized_url = sanitize_url(url)
    total_payloads = len(payloads)
    successful_tests = 0

    print(f"(+) {total_payloads} payload test ediliyor...")

    for i, payload in enumerate(payloads):
        response = send_xml_payload(sanitized_url, payload)
        
        if response is None:
            continue
        
        # Yanıt içinde XML hatası ya da hassas veriler var mı kontrol et
        if response.status_code == 200:
            if "error" in response.text.lower() or "exception" in response.text.lower():
                vulnerabilities_found.append(f"Olası XML zafiyeti: {sanitized_url} - Payload: {payload}")
            else:
                successful_tests += 1
    
    # Toplam test edilen payload sayısını ve zafiyet durumunu bildir
    print(f"(+) {total_payloads} payload testi tamamlandı.")
    
    # Formları ve linkleri listele
    print("\nBulunan Formlar:")
    for form in forms:
        print(f"Form action: {form.get('action')}, Method: {form.get('method', 'get').lower()}")
    
    print("\nBulunan Linkler:")
    for link in links:
        print(f"Link href: {link['href']}")

    if vulnerabilities_found:
        print("\nZafiyetler:")
        for vulnerability in vulnerabilities_found:
            print(vulnerability)
    else:
        print("(-) XML zafiyeti bulunamadı.")

    return vulnerabilities_found

def load_payloads(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            payloads = file.read().splitlines()
        return payloads
    except FileNotFoundError:
        print(f"(-) Payload dosyası bulunamadı: {file_path}")
        return []

def get_page_content(url, use_selenium=False):
    if use_selenium:
        # Selenium ile dinamik içeriği alıyorum
        from selenium import webdriver
        from selenium.webdriver.chrome.service import Service
        from selenium.webdriver.chrome.options import Options
        from webdriver_manager.chrome import ChromeDriverManager

        options = Options()
        options.headless = True  # Tarayıcıyı arka planda çalıştır
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

        driver.get(url)
        content = driver.page_source
        driver.quit()
        return content
    else:
        # Normal requests ile sayfa içeriğini alıyorum
        try:
            response = requests.get(url, verify=False)  # Sertifika doğrulamasını devre dışı bırak
            if response.status_code == 200:
                return response.text
            else:
                print(f"Sayfa Alınamadı. Statüs kod: {response.status_code}")
                return None
        except Exception as e:
            print(f"Bir hata oluştu: {e}")
            return None

def find_forms_and_links(url, use_selenium=False):
    content = get_page_content(url, use_selenium)
    if not content:
        return [], []

    soup = BeautifulSoup(content, 'html.parser')
    forms = soup.find_all('form')
    links = soup.find_all('a', href=True)

    print(f"Bulunan Formlar: {len(forms)}")
    print(f"Bulunan Linkler: {len(links)}")
    
    return forms, links

def main():
    parser = argparse.ArgumentParser(description='XML Vulnerability Scanner')
    parser.add_argument('url', help='Hedef URL')
    parser.add_argument('payloads_file', help='XML payloads dosyası')
    parser.add_argument('--use_selenium', action='store_true', help='Selenium kullanarak dinamik içeriği işlemek için')
    
    args = parser.parse_args()

    target_url = args.url
    payloads_file = args.payloads_file
    use_selenium = args.use_selenium

    print(f"(+) {payloads_file} dosyasından payload'lar yükleniyor...")
    payloads = load_payloads(payloads_file)
    
    if payloads:
        print(f"(+) {target_url} adresinde XML zafiyeti testi başlatılıyor...")
        forms, links = find_forms_and_links(target_url, use_selenium=use_selenium)
        check_xxe_injection(target_url, payloads, forms, links)
    else:
        print("(-) Yüklenecek payload bulunamadı.")

if __name__ == "__main__":
    main()
