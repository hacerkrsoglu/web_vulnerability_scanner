# -*- coding: utf-8 -*-
"""
Created on Wed Sep 11 23:32:16 2024

@author: Hacer
"""

import argparse
import requests
from bs4 import BeautifulSoup
import urllib.parse
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from requests.packages.urllib3.exceptions import InsecureRequestWarning
import warnings
from urllib.parse import urlparse, urlunparse

# Sertifika uyarılarını bastır
warnings.simplefilter('ignore', InsecureRequestWarning)
def get_page_content(url, use_selenium=False):
    if use_selenium:
        options = Options()
        options.headless = True
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
        driver.get(url)
        content = driver.page_source
        driver.quit()
        return content
    else:
        try:
            response = requests.get(url, verify=False)
            if response.status_code == 200:
                return response.text
            else:
                print(f"Sayfa Alınamadı. Statüs kod: {response.status_code}")
                return None
        except Exception as e:
            print(f"Bir hata oluştu: {e}")
            return None

def find_forms_and_links(url, use_selenium=False):
    content = get_page_content(url, use_selenium)
    if not content:
        return [], []

    soup = BeautifulSoup(content, 'html.parser')
    forms = soup.find_all('form')
    links = soup.find_all('a', href=True)

    print(f"Bulunan Formlar: {len(forms)}")
    print(f"Bulunan Linkler: {len(links)}")
    
    return forms, links

def sanitize_url(url):
    parsed_url = urlparse(url)
    scheme = parsed_url.scheme
    netloc = parsed_url.netloc
    path = parsed_url.path.rstrip('/')
    clean_url = urlunparse((scheme, netloc, path, '', '', ''))
    return clean_url

def is_within_scope(url, scope_domain):
    if scope_domain is None:
        return True
    parsed_url = urllib.parse.urlparse(url)
    return parsed_url.netloc.endswith(scope_domain)

def check_sql_injection(url, forms, links, payloads, scope_domain):
    vulnerabilities_found = []
    sanitized_url = sanitize_url(url)

    for form in forms:
        action = form.get('action')
        method = form.get('method', 'get').lower()
        inputs = form.find_all('input')
        form_data = {}

        for input_element in inputs:
            name = input_element.get('name')
            if name:
                form_data[name] = "test"

        for payload in payloads:
            for key in form_data.keys():
                form_data[key] = payload

            full_url = urllib.parse.urljoin(sanitized_url, action)
            if scope_domain is not None and not is_within_scope(full_url, scope_domain):
                continue

            if method == 'post':
                response = requests.post(full_url, data=form_data, verify=False)
            else:
                query_string = urllib.parse.urlencode(form_data)
                full_url = urllib.parse.urljoin(sanitized_url, action) + "?" + query_string
                response = requests.get(full_url, verify=False)

            if "error" in response.text.lower():
                vulnerabilities_found.append(f"Olası SQL Injection açığı formda bulundu: {full_url} - Payload: {payload}")

    for link in links:
        href = link['href']
        full_url = urllib.parse.urljoin(sanitized_url, href)
        if scope_domain is not None and not is_within_scope(full_url, scope_domain):
            continue

        for payload in payloads:
            test_url = full_url + urllib.parse.quote(payload)
            response = requests.get(test_url, verify=False)

            if "error" in response.text.lower():
                vulnerabilities_found.append(f"Olası SQL Injection açığı linkte bulundu: {test_url} - Payload: {payload}")

    return vulnerabilities_found

def load_payloads(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            payloads = file.read().splitlines()
        return payloads
    except Exception as e:
        print(f"{file_path}: {e} dosyasından yükleme başarısız oldu.")
        return []

def main():
    parser = argparse.ArgumentParser(description='SQL Injection Vulnerability Scanner')
    parser.add_argument('url', type=str, help='The URL of the web application to scan')
    parser.add_argument('payloads_file', type=str, help='Path to the SQL payloads file')
    parser.add_argument('scope_domain', type=str, help='Domain to restrict the scope of the scan')
    parser.add_argument('--use_selenium', action='store_true', help='Use Selenium to handle dynamic content')

    args = parser.parse_args()

  

    sql_payloads = load_payloads(args.payloads_file)
    forms, links = find_forms_and_links(args.url, args.use_selenium)
    
    if forms or links:
        vulnerabilities = check_sql_injection(args.url, forms, links, sql_payloads, args.scope_domain)
        if vulnerabilities:
            for vulnerability in vulnerabilities:
                print(vulnerability)
        else:
            print("SQL Injection açığı bulunamadı.")
    else:
        print("Form veya link bulunamadı.")

if __name__ == "__main__":
    main()